<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="description" content="">
    <meta name="author" content="">
    <!-- <link rel="icon" href="../../favicon.ico"> -->

    <title>Mental Imagery</title>

    <!-- Bootstrap core CSS -->
    <link href="../project_saliency/css/bootstrap.min.css" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Architects+Daughter" rel="stylesheet" type="text/css">
    <link href="../project_saliency/css/font-awesome.min.css" rel="stylesheet" type="text/css">

    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <!--<link href="../../assets/css/ie10-viewport-bug-workaround.css" rel="stylesheet">-->

    <!-- Custom styles for this template -->
    <link href="../project_saliency/ccs/jumbotron.css" rel="stylesheet">

    <!-- Just for debugging purposes. Don't actually copy these 2 lines! -->
    <!--[if lt IE 9]><script src="../../assets/js/ie8-responsive-file-warning.js"></script><![endif]-->
    <!--<script src="../../assets/js/ie-emulation-modes-warning.js"></script> -->

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->

    <!-- Google Analytics -->
    <script>
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
            m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

        ga('create', 'UA-61168812-1', 'auto');
        ga('send', 'pageview');

    </script>
    <!-- End Google Analytics -->

</head>

<body>

<!-- Fixed navbar -->
<nav class="navbar navbar-inverse navbar-fixed-top">
    <div class="container">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="index.html">Mental Imagery</a>
        </div>
        <div id="navbar" class="navbar-collapse collapse">
            <ul class="nav navbar-nav">
                <!--             <li><a href="index.html">Home</a></li> -->
                <li><a href="retrieval.html">Retrieval</a></li>
                <li><a href="similarity.html">Quantification</a></li>
                <li class="active"><a href="#">Elastic Matching</a></li>

            </ul>
        </div><!--/.nav-collapse -->
    </div>
</nav>


<!-- Main jumbotron for a primary marketing message or call to action -->
<div class="jumbotron">
    <div class="container">
        <h2>A consensus-based elastic matching algorithm for mapping recall fixations onto encoding fixations in the
            looking-at-nothing paradigm</h2>
        <h5>Behavior Research Method 2021</h5>
        <div class="author">
            <a href="https://xiwang1212.github.io/homepage/">Xi Wang,</a>
            <a href="http://www.cg.tu-berlin.de"> <small>(Computer Graphics, TU Berlin)</small></a>
            <a href="https://www.researchgate.net/profile/Kenneth_Holmqvist">&nbsp&nbsp&nbsp&nbsp Kenneth Holmqvist</a>
            <a href="http://www.cognition.tu-berlin.de/menue/modelling_of_cognitive_processes/"><small>(Universitaet Regensburg)</small></a>
            <a href="http://www.cg.tu-berlin.de/team/prof-dr-marc-alexa/">&nbsp&nbsp&nbsp&nbsp Marc Alexa</a>
            <a href="http://www.cg.tu-berlin.de"><small>(Computer Graphics, TU Berlin)</small></a>
        </div>

    </div>
</div>
</div>

<div class="container">

    <h3 class="featurette-heading">Abstract</h3>
    <p>
        We present an algorithmic method for aligning recall fixations with encoding fixations, to be used in
        looking-at-nothing paradigms that either record recall eye movements during silence or want to speed up data
        analysis with recordings of recall data during speech. The algorithm utilizes a novel consensus-based elastic
        matching algorithm to estimate which encoding fixations correspond to later recall fixations.
        This is not a scanpath comparison method, as fixation sequence order is ignored and only position configurations
        are used. The algorithm has three internal parameters and is reasonable stable over a wide range of parameter
        values. We then evaluate the performance of our algorithm by investigating whether the recalled objects
        identified by the algorithm correspond with independent assessments of what objects in the image are marked as
        subjectively important. Our results show that the mapped recall fixations align well with important regions of
        the images. This result is exemplified in four groups of use cases: to investigate the roles of low-level visual
        features, faces, signs and text, and people of different sizes, in recall of encoded scenes. The plots from
        these examples corroborate the finding that the algorithm aligns recall fixations with the most likely important
        regions in the images. Examples also illustrate how the algorithm can differentiate between image objects that
        have been fixated during silent recall vs those objects that have not been visually attended, even though they
        were fixated during encoding.
    </p>
    <br>

    <div>
        <h3>Dataset</h3>
        <ul>
            <li><h4>Image stimuli<small><a href="http://cybertron.cg.tu-berlin.de/xiwang/mental_imagery/dataset/images.zip"> [12 MB zipped]</a></small></h4></li>
            <li><h4>Fixation data<small><a href="http://cybertron.cg.tu-berlin.de/xiwang/mental_imagery/dataset/imgData.zip"> [2 MB zipped]</a></small></h4></li>
        </ul>

    </div>
    <div>
        <h3>Source code</h3>
        <ul>
            <li><h4><a href="https://github.com/x-wang/em"> GitHub</a></h4></li>
        </ul>
    </div>

    <hr>

    <div>
        <h3>Acknowledgments</h3>
        <p>
            We would like to thank Marianne Maertens for valuable advice. Furthermore, we thank all participants for joining the experiment.
        </p>
    </div>

    <footer>
        <p></p>
    </footer>
</div> <!-- /container -->


<!-- Bootstrap core JavaScript
================================================== -->
<!-- Placed at the end of the document so the pages load faster -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="../../assets/js/vendor/jquery.min.js"><\/script>')</script>
<script src="../../dist/js/bootstrap.min.js"></script>
<!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
<script src="../../assets/js/ie10-viewport-bug-workaround.js"></script>
</body>
</html>
